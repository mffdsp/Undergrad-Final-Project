## autogenerated

# # step 0: train loss 4.7242, val loss 4.7259
# # step 250: train loss 2.4860, val loss 2.4864
# # step 500: train loss 2.1405, val loss 2.1777
# # step 750: train loss 1.8335, val loss 1.9221
# # step 1000: train loss 1.6188, val loss 1.7573
# # step 1250: train loss 1.5081, val loss 1.6561
# # step 1500: train loss 1.4305, val loss 1.5960
# # step 1750: train loss 1.3747, val loss 1.5508
# # step 2000: train loss 1.3323, val loss 1.5252
# # step 2250: train loss 1.3056, val loss 1.4979
# # step 2500: train loss 1.2796, val loss 1.4799
# # step 2750: train loss 1.2694, val loss 1.4680
# # step 3000: train loss 1.2449, val loss 1.4511
# # step 3250: train loss 1.2229, val loss 1.4314
# # step 3500: train loss 1.2023, val loss 1.4180
# # step 3750: train loss 1.1803, val loss 1.4172
# # step 4000: train loss 1.1607, val loss 1.4010
# # step 4250: train loss 1.1676, val loss 1.3975
# # step 4500: train loss 1.1414, val loss 1.3898
# # step 4750: train loss 1.1289, val loss 1.3783
# # step 5000: train loss 1.1262, val loss 1.3704
# # step 5250: train loss 1.1131, val loss 1.3636
# # step 5500: train loss 1.1152, val loss 1.3626
# # step 5750: train loss 1.1039, val loss 1.3580
# # step 5999: train loss 1.0894, val loss 1.3489

# step 0: train loss 4.7242, val loss 4.7259
# step 250: train loss 2.4856, val loss 2.4862
# step 500: train loss 2.1409, val loss 2.1785
# step 750: train loss 1.8335, val loss 1.9228
# step 1000: train loss 1.6185, val loss 1.7559
# step 1250: train loss 1.5101, val loss 1.6605
# step 1500: train loss 1.4310, val loss 1.5959
# step 1750: train loss 1.3740, val loss 1.5533
# step 2000: train loss 1.3307, val loss 1.5239
# step 2250: train loss 1.3066, val loss 1.4993
# step 2500: train loss 1.2761, val loss 1.4775
# step 2750: train loss 1.2655, val loss 1.4634
# step 3000: train loss 1.2463, val loss 1.4540
# step 3250: train loss 1.2261, val loss 1.4355
# step 3500: train loss 1.2041, val loss 1.4214
# step 3750: train loss 1.1816, val loss 1.4176
# step 4000: train loss 1.1633, val loss 1.4042
# step 4250: train loss 1.1668, val loss 1.3951
# step 4500: train loss 1.1414, val loss 1.3897

# # DATA
# steps = [0, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, 3250, 3500, 3750, 4000, 4250, 4500, 4750, 5000, 5250, 5500, 5750, 5999]
# train_loss = [4.7242, 2.4860, 2.1405, 1.8335, 1.6188, 1.5081, 1.4305, 1.3747, 1.3323, 1.3056, 1.2796, 1.2694, 1.2449, 1.2229, 1.2023, 1.1803, 1.1607, 1.1676, 1.1414, 1.1289, 1.1262, 1.1131, 1.1152, 1.1039, 1.0894]
# val_loss = [4.7259, 2.4864, 2.1777, 1.9221, 1.7573, 1.6561, 1.5960, 1.5508, 1.5252, 1.4979, 1.4799, 1.4680, 1.4511, 1.4314, 1.4180, 1.4172, 1.4010, 1.3975, 1.3898, 1.3783, 1.3704, 1.3636, 1.3626, 1.3580, 1.3489]

# # Plot
# plt.plot(steps, train_loss, label='Train Loss')
# plt.plot(steps, val_loss, label='Validation Loss')
# plt.xlabel('Step')
# plt.ylabel('Loss')
# plt.title('Train Loss vs Validation Loss')
# plt.legend()
# plt.show()

# 10.818151 M parameters
# step 0: train loss 4.7242, val loss 4.7259
# step 250: train loss 2.4309, val loss 2.4864
# step 500: train loss 2.1309, val loss 2.1836
# step 1000: train loss 1.6201, val loss 1.7537
# step 1500: train loss 1.4340, val loss 1.6005
# step 2000: train loss 1.3366, val loss 1.5204
# step 2500: train loss 1.2765, val loss 1.4783
# step 3000: train loss 1.2398, val loss 1.4462
# step 3500: train loss 1.2042, val loss 1.4216
# step 4000: train loss 1.1723, val loss 1.3976
# step 4500: train loss 1.1459, val loss 1.3819
# step 5000: train loss 1.1270, val loss 1.3707
# step 5500: train loss 1.1029, val loss 1.3590
# step 5999: train loss 1.0929, val loss 1.3510
