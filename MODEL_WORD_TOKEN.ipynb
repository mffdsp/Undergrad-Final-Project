{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchtext.transforms import SentencePieceTokenizer\n",
    "from torch.hub import load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/data.txt'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer base hyperparams\n",
    "block_size = 256\n",
    "batch_size = 64\n",
    "max_iters = 8000\n",
    "eval_interval = 1000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Model Size\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "\n",
    "# Regularization || Optimization\n",
    "dropout = 0.2\n",
    "weight_decay = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORK IN PROGRESS (WORD TOKEN LEVEL NOT COVERED INTO THE UNDERGRAD PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "\n",
    "\n",
    "## https://colab.research.google.com/drive/1M7pDk5bbZh_wB4GMtVjDqVG2l9hCK1Wk#scrollTo=deaBhgnc1hGq\n",
    "\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "\n",
    "vocab = torch.load(\"xlmr.vocab.pt\")\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    tokens = tokenize_text(s)\n",
    "    return [vocab[token] for token in tokens]\n",
    "\n",
    "\n",
    "def decode(l):\n",
    "    tokens = [key for key, value in vocab.items() if value in l]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
